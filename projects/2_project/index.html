<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>MMLA in Debriefs | Vitaliy Popov</title> <meta name="author" content="Vitaliy Popov"/> <meta name="description" content="Multimodal Analysis of Student Cognitive and Emotional Responses during Team Debriefs"/> <meta name="keywords" content="CSCL, CSCW, team, simulation, learning analytics, educational technology"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="/assets/img/prof_pic.jpg"/> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://vpopov1.github.io/projects/2_project/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://vpopov1.github.io/"><span class="font-weight-bold">Vitaliy</span> Popov</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">TIME Lab</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/projects/">projects</a> </div> </li> <div class="toggle-container"> <a id="light-toggle"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </a> </div> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">MMLA in Debriefs</h1> <p class="post-description">Multimodal Analysis of Student Cognitive and Emotional Responses during Team Debriefs</p> </header> <article> <p>In the medical field, the technique of “breaking bad news” is incredibly important for future doctors and social workers to practice and receive meaningful feedback on. Our research team transcribed, analyzed, and annotated over 150 standardized patient simulation videos. A novel methodology was employed for multimodal sentiment analysis, which consists of gathering sentiments from available simulation videos by extracting audio, visual, and textual data features as inputs for multimodal modeling. Then, these data streams were used to predict and classify a trainee’s emotional states when receiving feedback. Overall, the goal is to optimize the feedback delivery and reception in order to prepare future medical professionals for the critical task of delivering bad news.</p> <div class="row justify-content-sm-center"> <div class="col-md-12 mt-3 mt-md-0"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/fmodel-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/fmodel-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/fmodel-1400.webp"></source> <img class="img-fluid rounded z-depth-1" src="/assets/img/fmodel.png" title="example image"> </picture> </figure> </div> <div class="caption"> Feedback in team-based post-simulation debriefings. Source: adapted from Gabelica &amp; Popov, 2020 </div> <p class="font-weight-bold">Guiding Research Questions:</p> (1) How do medical and social work students reflect, perceive and process information cues contained in feedback during BBN debrief sessions? (2) Can we leverage machine learning to build a sentiment classifier, so we can reliably predict in near-real time student engagement in the debrief process? <div class="row justify-content-sm-center"> <div class="col-md-10 mt-3 mt-md-0"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/mmodel-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/mmodel-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/mmodel-1400.webp"></source> <img class="img-fluid rounded z-depth-1" src="/assets/img/mmodel.png" title="example image"> </picture> </figure> </div> <div class="caption"> Multimodal Sentiment Analysis overview: detect and classify sentiment by analyzing data from multiple modalities (visual, auditory and textual modalities in our case). </div> <div class="row justify-content-sm-center"> <div class="col-md-10 mt-3 mt-md-0"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/mmodel1-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/mmodel1-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/mmodel1-1400.webp"></source> <img class="img-fluid rounded z-depth-1" src="/assets/img/mmodel1.png" title="example image"> </picture> </figure> </div> <div class="caption"> We used OpenPose - a toolkit to jointly detect human body, hand, facial, and foot postures as keypoints on video frames. </div> The relationship between emotion and feedback is complex. This research is valuable to the future of medical education, as analyzing the quality of feedback given can help to optimize these patient simulations and better prepare medical students for real-life situations. The research team continues to develop system for automatic quantification and interpretation of an individual’s sentiment when receiving feedback based on verbal and nonverbal behavior, such as words (speech content), head and body movements, facial expressions (when possible given camera angle), tone of voice, eye gaze, and turn taking. <div class="row justify-content-sm-center"> <div class="col-md-10 mt-3 mt-md-0"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/mmodel2-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/mmodel2-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/mmodel2-1400.webp"></source> <img class="img-fluid rounded z-depth-1" src="/assets/img/mmodel2.png" title="example image"> </picture> </figure> </div> <div class="caption"> An example of a sentiment classifier in action with the idea of reliably predicting student perception and processing of feedback in the post-simulation debriefs. </div> <b>TEAM MEMBERS:</b> <b>Zhaoyuan Zhang</b>, MS student, <b>Yiqun Yao</b>, postdoctoral research fellow at the University of Michigan, <b>Ava Gizoni</b>, student, <b>Nicole Meimaris</b>, student, <b>Coco Yu</b>, student. </div> </div> </div> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Vitaliy Popov. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a>. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script src="/assets/js/zoom.js"></script> <script src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id="></script> <script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","");</script> </body> </html>